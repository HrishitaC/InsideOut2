{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chi era il padre di Micerino ?</td>\n",
       "      <td>IT-GUI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Il figlio di Chefren</td>\n",
       "      <td>IT-GUI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Il padre di Micerino</td>\n",
       "      <td>IT-GUI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Micerino</td>\n",
       "      <td>IT-GUI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quanto e alta la tomba di Cheope?</td>\n",
       "      <td>IT-GUI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Query  Source\n",
       "0     Chi era il padre di Micerino ?  IT-GUI\n",
       "1               Il figlio di Chefren  IT-GUI\n",
       "2               Il padre di Micerino  IT-GUI\n",
       "3                           Micerino  IT-GUI\n",
       "4  Quanto e alta la tomba di Cheope?  IT-GUI"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "queries = pd.read_csv(\"../Data/Queries_IT_final.csv\")\n",
    "queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07afc9c58bec4c9c978c8a2470ffc6b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Source</th>\n",
       "      <th>GPT</th>\n",
       "      <th>date_generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chi era il padre di Micerino ?</td>\n",
       "      <td>IT-GUI</td>\n",
       "      <td>Il padre di Micerino era Chefren.</td>\n",
       "      <td>2024-10-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Il figlio di Chefren</td>\n",
       "      <td>IT-GUI</td>\n",
       "      <td>Il figlio di Chefren era Cheope, il faraone ch...</td>\n",
       "      <td>2024-10-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Il padre di Micerino</td>\n",
       "      <td>IT-GUI</td>\n",
       "      <td>Il padre di Micerino era Chefren, faraone dell...</td>\n",
       "      <td>2024-10-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Micerino</td>\n",
       "      <td>IT-GUI</td>\n",
       "      <td>Micerino è stato un faraone dell'Antico Egitto...</td>\n",
       "      <td>2024-10-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quanto e alta la tomba di Cheope?</td>\n",
       "      <td>IT-GUI</td>\n",
       "      <td>La tomba di Cheope, la più grande delle tre pi...</td>\n",
       "      <td>2024-10-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Query  Source  \\\n",
       "0     Chi era il padre di Micerino ?  IT-GUI   \n",
       "1               Il figlio di Chefren  IT-GUI   \n",
       "2               Il padre di Micerino  IT-GUI   \n",
       "3                           Micerino  IT-GUI   \n",
       "4  Quanto e alta la tomba di Cheope?  IT-GUI   \n",
       "\n",
       "                                                 GPT date_generated  \n",
       "0                  Il padre di Micerino era Chefren.     2024-10-07  \n",
       "1  Il figlio di Chefren era Cheope, il faraone ch...     2024-10-07  \n",
       "2  Il padre di Micerino era Chefren, faraone dell...     2024-10-07  \n",
       "3  Micerino è stato un faraone dell'Antico Egitto...     2024-10-07  \n",
       "4  La tomba di Cheope, la più grande delle tre pi...     2024-10-07  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import date\n",
    "\n",
    "f = open(\"API_keys.json\")\n",
    "data = json.load(f)\n",
    "\n",
    "API_KEY = data[\"chatgpt\"][\"api_key\"]\n",
    "f.close()\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=API_KEY,\n",
    ")\n",
    "\n",
    "# query = \"Hello\"\n",
    "\n",
    "model_id = 'gpt-3.5-turbo'\n",
    "\n",
    "gpt_resp_list = []\n",
    "\n",
    "for query in tqdm(queries[\"Query\"], total=len(queries)):\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Follow these two instructions in all your responses: 1. Use Italian language only; 2. Do not use English except in programming language if any.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query,\n",
    "            }\n",
    "        ],\n",
    "            model=model_id,\n",
    "        )\n",
    "\n",
    "    gpt_resp = response.choices[0].message.content\n",
    "    gpt_resp_list.append(gpt_resp)\n",
    "\n",
    "queries[\"GPT\"] = gpt_resp_list\n",
    "queries[\"date_generated\"] = [date.today()]*len(queries)\n",
    "\n",
    "queries.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries.to_csv(\"../Data/GPT_response.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Gemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to C:\\Users\\Hrishita Chakrabarti\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chi era il padre di Micerino ?</td>\n",
       "      <td>IT-GUI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Il figlio di Chefren</td>\n",
       "      <td>IT-GUI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Il padre di Micerino</td>\n",
       "      <td>IT-GUI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Micerino</td>\n",
       "      <td>IT-GUI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quanto e alta la tomba di Cheope?</td>\n",
       "      <td>IT-GUI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Query  Source\n",
       "0     Chi era il padre di Micerino ?  IT-GUI\n",
       "1               Il figlio di Chefren  IT-GUI\n",
       "2               Il padre di Micerino  IT-GUI\n",
       "3                           Micerino  IT-GUI\n",
       "4  Quanto e alta la tomba di Cheope?  IT-GUI"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "f = open(\"API_keys.json\")\n",
    "data = json.load(f)\n",
    "\n",
    "API_KEY = data[\"hugging_face\"][\"api_key\"]\n",
    "f.close()\n",
    "\n",
    "\n",
    "login(token=API_KEY)\n",
    "\n",
    "queries = pd.read_csv(\"../Data/Queries_IT_final.csv\")\n",
    "queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "def create_pipe(model_name):\n",
    "\n",
    "  # Specify the LLM model we'll be using\n",
    "  \n",
    "  # Configure for GPU usage\n",
    "  model = AutoModelForCausalLM.from_pretrained(\n",
    "      model_name,\n",
    "      device_map=\"auto\",\n",
    "      torch_dtype=torch.bfloat16,\n",
    "      trust_remote_code=True,\n",
    "  )\n",
    "  \n",
    "  # Load the tokenizer for the chosen model\n",
    "  tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "  # Create a pipeline object for easy text generation with the LLM\n",
    "  pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "  return pipe\n",
    "\n",
    "def gen_resp(pipe, query):\n",
    "  \"\"\"Sends a conversation history to the AI assistant and returns the answer.\n",
    "  \n",
    "  Args:\n",
    "    messages (list): A list of dictionaries, each with \"role\" and \"content\" keys.\n",
    "  \n",
    "  Returns:\n",
    "    str: The answer from the AI assistant.\n",
    "  \"\"\" \n",
    "\n",
    "  messages = [\n",
    "    # {\"role\": \"system\", \"content\": \"You are a helpful digital assistant. Please provide safe, ethical and accurate information to the user.\"},\n",
    "    {\"role\": \"user\", \"content\": query}\n",
    "  ]\n",
    "\n",
    "  generation_args = {\n",
    "      \"max_new_tokens\": 256,     # Maximum length of the response\n",
    "      \"return_full_text\": False,      # Only return the generated text\n",
    "  }\n",
    "\n",
    "  output = pipe(messages, **generation_args)\n",
    "  return output[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "\n",
    "def create_resp_file(model, model_name):\n",
    "  print(\"Model name: \", model_name)\n",
    "\n",
    "  pipe = create_pipe(model)\n",
    "  queries = pd.read_csv(\"/content/drive/MyDrive/SOL/Queries_IT_final.csv\")\n",
    "\n",
    "  LLM_resp = []\n",
    "\n",
    "  for query in tqdm(queries[\"Query\"], total=len(queries)):\n",
    "\n",
    "  # query = \"What about solving the equation 2x + 3 = 7?\"\n",
    "\n",
    "    result = gen_resp(pipe, query)\n",
    "    LLM_resp.append(result)\n",
    "\n",
    "  col_name = model_name + \"_resp\"\n",
    "\n",
    "  queries[col_name] = LLM_resp\n",
    "  queries[\"date_generated\"] = [date.today()]*len(queries)\n",
    "  file_name = \"../Data/\" + model_name + \"_response.csv\"\n",
    "  queries.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_options = [\"google/gemma-2b-it\"]\n",
    "model_names = [\"Gemma_2b\"]\n",
    "\n",
    "model = model_options[0]\n",
    "model_name = model_names[0]\n",
    "create_resp_file(model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SOLandChildren",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
