{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chi era il padre di Micerino ?</td>\n",
       "      <td>IT-GUI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Il figlio di Chefren</td>\n",
       "      <td>IT-GUI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Il padre di Micerino</td>\n",
       "      <td>IT-GUI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Micerino</td>\n",
       "      <td>IT-GUI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quanto e alta la tomba di Cheope?</td>\n",
       "      <td>IT-GUI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Query  Source\n",
       "0     Chi era il padre di Micerino ?  IT-GUI\n",
       "1               Il figlio di Chefren  IT-GUI\n",
       "2               Il padre di Micerino  IT-GUI\n",
       "3                           Micerino  IT-GUI\n",
       "4  Quanto e alta la tomba di Cheope?  IT-GUI"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "queries = pd.read_csv(\"../Data/Queries_IT_final.csv\")\n",
    "queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import date\n",
    "\n",
    "f = open(\"API_keys.json\")\n",
    "data = json.load(f)\n",
    "\n",
    "API_KEY = data[\"chatgpt\"][\"api_key\"]\n",
    "f.close()\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=API_KEY,\n",
    ")\n",
    "\n",
    "# query = \"Hello\"\n",
    "\n",
    "model_id = 'gpt-3.5-turbo'\n",
    "\n",
    "def get_gpt_resp(query):\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Follow these two instructions in all your responses: 1. Use Italian language only; 2. Do not use English except in programming language if any.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query,\n",
    "            }\n",
    "        ],\n",
    "            model=model_id,\n",
    "        )\n",
    "\n",
    "    gpt_resp = response.choices[0].message.content\n",
    "\n",
    "    return gpt_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d62239500f4f86a53096e755cea51d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Query</th>\n",
       "      <th>Reformed Query</th>\n",
       "      <th>Gender</th>\n",
       "      <th>GPT</th>\n",
       "      <th>date_generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chi era il padre di Micerino ?</td>\n",
       "      <td>La seguente domanda è rivolta da un bambino di...</td>\n",
       "      <td>male</td>\n",
       "      <td>Il padre di Micerino era Chefren.</td>\n",
       "      <td>2024-10-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chi era il padre di Micerino ?</td>\n",
       "      <td>La seguente domanda è rivolta da un bambino di...</td>\n",
       "      <td>female</td>\n",
       "      <td>Il padre di Micerino era Chefren. Chefren è co...</td>\n",
       "      <td>2024-10-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Il figlio di Chefren</td>\n",
       "      <td>La seguente domanda è rivolta da un bambino di...</td>\n",
       "      <td>male</td>\n",
       "      <td>Mi dispiace, ma non posso fornire risposte a d...</td>\n",
       "      <td>2024-10-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Il figlio di Chefren</td>\n",
       "      <td>La seguente domanda è rivolta da un bambino di...</td>\n",
       "      <td>female</td>\n",
       "      <td>Il figlio di Chefren è Micerino. Chefren è sta...</td>\n",
       "      <td>2024-10-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Il padre di Micerino</td>\n",
       "      <td>La seguente domanda è rivolta da un bambino di...</td>\n",
       "      <td>male</td>\n",
       "      <td>Il padre di Micerino si chiamava Chefren ed er...</td>\n",
       "      <td>2024-10-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Original Query  \\\n",
       "0  Chi era il padre di Micerino ?   \n",
       "1  Chi era il padre di Micerino ?   \n",
       "2            Il figlio di Chefren   \n",
       "3            Il figlio di Chefren   \n",
       "4            Il padre di Micerino   \n",
       "\n",
       "                                      Reformed Query  Gender  \\\n",
       "0  La seguente domanda è rivolta da un bambino di...    male   \n",
       "1  La seguente domanda è rivolta da un bambino di...  female   \n",
       "2  La seguente domanda è rivolta da un bambino di...    male   \n",
       "3  La seguente domanda è rivolta da un bambino di...  female   \n",
       "4  La seguente domanda è rivolta da un bambino di...    male   \n",
       "\n",
       "                                                 GPT date_generated  \n",
       "0                  Il padre di Micerino era Chefren.     2024-10-15  \n",
       "1  Il padre di Micerino era Chefren. Chefren è co...     2024-10-15  \n",
       "2  Mi dispiace, ma non posso fornire risposte a d...     2024-10-15  \n",
       "3  Il figlio di Chefren è Micerino. Chefren è sta...     2024-10-15  \n",
       "4  Il padre di Micerino si chiamava Chefren ed er...     2024-10-15  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_resp_list = []\n",
    "\n",
    "for query in tqdm(queries[\"Query\"], total=len(queries)):\n",
    "\n",
    "    reformed_query_male = \"La seguente domanda è rivolta da un bambino di 10 anni mentre sta svolgendo i compiti di quarta elementare: \" + query\n",
    "    reformed_query_female = \"La seguente domanda è rivolta da una bambina di 10 anni mentre sta svolgendo i compiti di quarta elementare: \" + query\n",
    "\n",
    "    gpt_resp = get_gpt_resp(reformed_query_male)\n",
    "    gpt_resp_list.append([query, reformed_query_male, \"male\", gpt_resp, date.today()])\n",
    "\n",
    "    gpt_resp = get_gpt_resp(reformed_query_female)\n",
    "    gpt_resp_list.append([query, reformed_query_male, \"female\", gpt_resp, date.today()])\n",
    "\n",
    "\n",
    "\n",
    "queries = pd.DataFrame(gpt_resp_list, columns=[\"Original Query\", \"Reformed Query\", \"Gender\", \"GPT\", \"date_generated\"])\n",
    "queries.to_csv(\"../Data/GPT_response_RQ.csv\", index=False)\n",
    "\n",
    "queries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Gemma\n",
    "\n",
    "Executed using [Google Colab](https://colab.research.google.com/drive/1rjahUz6MaHW6wj5eL5F-C4p2r47GnnmA?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to C:\\Users\\Hrishita Chakrabarti\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chi era il padre di Micerino ?</td>\n",
       "      <td>IT-GUI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Il figlio di Chefren</td>\n",
       "      <td>IT-GUI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Il padre di Micerino</td>\n",
       "      <td>IT-GUI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Micerino</td>\n",
       "      <td>IT-GUI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quanto e alta la tomba di Cheope?</td>\n",
       "      <td>IT-GUI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Query  Source\n",
       "0     Chi era il padre di Micerino ?  IT-GUI\n",
       "1               Il figlio di Chefren  IT-GUI\n",
       "2               Il padre di Micerino  IT-GUI\n",
       "3                           Micerino  IT-GUI\n",
       "4  Quanto e alta la tomba di Cheope?  IT-GUI"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "f = open(\"API_keys.json\")\n",
    "data = json.load(f)\n",
    "\n",
    "API_KEY = data[\"hugging_face\"][\"api_key\"]\n",
    "f.close()\n",
    "\n",
    "\n",
    "login(token=API_KEY)\n",
    "\n",
    "queries = pd.read_csv(\"../Data/Queries_IT_final.csv\")\n",
    "queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "def create_pipe(model_name):\n",
    "\n",
    "  # Specify the LLM model we'll be using\n",
    "  \n",
    "  # Configure for GPU usage\n",
    "  model = AutoModelForCausalLM.from_pretrained(\n",
    "      model_name,\n",
    "      device_map=\"auto\",\n",
    "      torch_dtype=torch.bfloat16,\n",
    "      trust_remote_code=True,\n",
    "  )\n",
    "  \n",
    "  # Load the tokenizer for the chosen model\n",
    "  tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "  # Create a pipeline object for easy text generation with the LLM\n",
    "  pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "  return pipe\n",
    "\n",
    "def gen_resp(pipe, query):\n",
    "  \"\"\"Sends a conversation history to the AI assistant and returns the answer.\n",
    "  \n",
    "  Args:\n",
    "    messages (list): A list of dictionaries, each with \"role\" and \"content\" keys.\n",
    "  \n",
    "  Returns:\n",
    "    str: The answer from the AI assistant.\n",
    "  \"\"\" \n",
    "\n",
    "  messages = [\n",
    "    # {\"role\": \"system\", \"content\": \"You are a helpful digital assistant. Please provide safe, ethical and accurate information to the user.\"},\n",
    "    {\"role\": \"user\", \"content\": query}\n",
    "  ]\n",
    "\n",
    "  generation_args = {\n",
    "      \"max_new_tokens\": 256,     # Maximum length of the response\n",
    "      \"return_full_text\": False,      # Only return the generated text\n",
    "  }\n",
    "\n",
    "  output = pipe(messages, **generation_args)\n",
    "  return output[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "\n",
    "def create_resp_file(model, model_name):\n",
    "  print(\"Model name: \", model_name)\n",
    "\n",
    "  pipe = create_pipe(model)\n",
    "  queries = pd.read_csv(\"/content/drive/MyDrive/SOL/Queries_IT_final.csv\")\n",
    "\n",
    "  LLM_resp = []\n",
    "\n",
    "  for query in tqdm(queries[\"Query\"], total=len(queries)):\n",
    "\n",
    "    reformed_query_male = \"La seguente domanda è rivolta da un bambino di 10 anni mentre sta svolgendo i compiti di quarta elementare: \" + query\n",
    "    reformed_query_female = \"La seguente domanda è rivolta da una bambina di 10 anni mentre sta svolgendo i compiti di quarta elementare: \" + query\n",
    "\n",
    "    result = gen_resp(pipe, reformed_query_male)\n",
    "    LLM_resp.append([query, reformed_query_male, \"male\", result, date.today()])\n",
    "    result = gen_resp(pipe, reformed_query_female)\n",
    "    LLM_resp.append([query, reformed_query_female, \"female\", result, date.today()])\n",
    "\n",
    "  col_name = model_name + \"_resp\"\n",
    "\n",
    "  queries = pd.DataFrame(LLM_resp, columns=[\"Original Query\", \"Reformed Query\", \"Gender\", col_name, \"date_generated\"])\n",
    "\n",
    "  file_name = \"/content/drive/MyDrive/SOL/\" + model_name + \"_response_RQ.csv\"\n",
    "  queries.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_options = [\"google/gemma-2b-it\", \"google/gemma-2-9b-it\", \"meta-llama/Meta-Llama-3.1-8B-Instruct\", \"mistralai/Mistral-7B-Instruct-v0.2\"]\n",
    "model_names = [\"Gemma_2b\", \"Gemma_2_9b\", \"Llama\", \"Mistral\"]\n",
    "\n",
    "model = model_options[0]\n",
    "model_name = model_names[0]\n",
    "create_resp_file(model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SOLandChildren",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
