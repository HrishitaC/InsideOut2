{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>source</th>\n",
       "      <th>query_len</th>\n",
       "      <th>topic</th>\n",
       "      <th>search_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chi era il padre di Micerino ?</td>\n",
       "      <td>IT-GUI</td>\n",
       "      <td>6</td>\n",
       "      <td>history</td>\n",
       "      <td>multisteps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Il figlio di Chefren</td>\n",
       "      <td>IT-GUI</td>\n",
       "      <td>4</td>\n",
       "      <td>history</td>\n",
       "      <td>multisteps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Il padre di Micerino</td>\n",
       "      <td>IT-GUI</td>\n",
       "      <td>4</td>\n",
       "      <td>history</td>\n",
       "      <td>multisteps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Micerino</td>\n",
       "      <td>IT-GUI</td>\n",
       "      <td>1</td>\n",
       "      <td>history</td>\n",
       "      <td>multisteps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quanto e alta la tomba di Cheope?</td>\n",
       "      <td>IT-GUI</td>\n",
       "      <td>7</td>\n",
       "      <td>history</td>\n",
       "      <td>fact</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               query  source  query_len    topic search_type\n",
       "0     Chi era il padre di Micerino ?  IT-GUI          6  history  multisteps\n",
       "1               Il figlio di Chefren  IT-GUI          4  history  multisteps\n",
       "2               Il padre di Micerino  IT-GUI          4  history  multisteps\n",
       "3                           Micerino  IT-GUI          1  history  multisteps\n",
       "4  Quanto e alta la tomba di Cheope?  IT-GUI          7  history        fact"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "queries = pd.read_csv(\"../Data/Queries_IT_final.csv\")\n",
    "queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import date\n",
    "\n",
    "f = open(\"API_keys.json\")\n",
    "data = json.load(f)\n",
    "\n",
    "API_KEY = data[\"chatgpt\"][\"api_key\"]\n",
    "f.close()\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=API_KEY,\n",
    ")\n",
    "\n",
    "# query = \"Hello\"\n",
    "\n",
    "model_id = 'gpt-3.5-turbo'\n",
    "\n",
    "def get_gpt_resp(query):\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Follow these two instructions in all your responses: 1. Use Italian language only; 2. Do not use English except in programming language if any.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query,\n",
    "            }\n",
    "        ],\n",
    "            model=model_id,\n",
    "        )\n",
    "\n",
    "    gpt_resp = response.choices[0].message.content\n",
    "\n",
    "    return gpt_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "690bc0668ee94dbcac532e3b108d4e39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Query</th>\n",
       "      <th>Reformed Query</th>\n",
       "      <th>Gender</th>\n",
       "      <th>GPT</th>\n",
       "      <th>date_generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chi era il padre di Micerino ?</td>\n",
       "      <td>La seguente domanda è rivolta da un bambino di...</td>\n",
       "      <td>male</td>\n",
       "      <td>Il padre di Micerino era Chefren.</td>\n",
       "      <td>2024-10-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chi era il padre di Micerino ?</td>\n",
       "      <td>La seguente domanda è rivolta da un bambino di...</td>\n",
       "      <td>female</td>\n",
       "      <td>Il padre di Micerino era Chefren. Chefren è co...</td>\n",
       "      <td>2024-10-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Il figlio di Chefren</td>\n",
       "      <td>La seguente domanda è rivolta da un bambino di...</td>\n",
       "      <td>male</td>\n",
       "      <td>Mi dispiace, ma non posso fornire risposte a d...</td>\n",
       "      <td>2024-10-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Il figlio di Chefren</td>\n",
       "      <td>La seguente domanda è rivolta da un bambino di...</td>\n",
       "      <td>female</td>\n",
       "      <td>Il figlio di Chefren è Micerino. Chefren è sta...</td>\n",
       "      <td>2024-10-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Il padre di Micerino</td>\n",
       "      <td>La seguente domanda è rivolta da un bambino di...</td>\n",
       "      <td>male</td>\n",
       "      <td>Il padre di Micerino si chiamava Chefren ed er...</td>\n",
       "      <td>2024-10-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>tornado velocita mostro nero</td>\n",
       "      <td>La seguente domanda è rivolta da una persona d...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Ciao! Posso aiutarti a capire meglio di cosa h...</td>\n",
       "      <td>2024-10-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>velocita tornado</td>\n",
       "      <td>La seguente domanda è rivolta da una persona d...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Mi dispiace, posso offrirti informazioni solo ...</td>\n",
       "      <td>2024-10-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>vulcani tipologia di eruzioni danni</td>\n",
       "      <td>La seguente domanda è rivolta da una persona d...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>I vulcani possono avere diversi tipi di eruzio...</td>\n",
       "      <td>2024-10-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>vulcano attivo antico</td>\n",
       "      <td>La seguente domanda è rivolta da una persona d...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Un vulcano attivo antico potrebbe essere il Ve...</td>\n",
       "      <td>2024-10-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>vulcano piÃ¹ antico attivo</td>\n",
       "      <td>La seguente domanda è rivolta da una persona d...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Il vulcano più antico attivo al mondo è l'Etna...</td>\n",
       "      <td>2024-10-27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>330 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Original Query  \\\n",
       "0         Chi era il padre di Micerino ?   \n",
       "1         Chi era il padre di Micerino ?   \n",
       "2                   Il figlio di Chefren   \n",
       "3                   Il figlio di Chefren   \n",
       "4                   Il padre di Micerino   \n",
       "..                                   ...   \n",
       "105         tornado velocita mostro nero   \n",
       "106                     velocita tornado   \n",
       "107  vulcani tipologia di eruzioni danni   \n",
       "108                vulcano attivo antico   \n",
       "109           vulcano piÃ¹ antico attivo   \n",
       "\n",
       "                                        Reformed Query   Gender  \\\n",
       "0    La seguente domanda è rivolta da un bambino di...     male   \n",
       "1    La seguente domanda è rivolta da un bambino di...   female   \n",
       "2    La seguente domanda è rivolta da un bambino di...     male   \n",
       "3    La seguente domanda è rivolta da un bambino di...   female   \n",
       "4    La seguente domanda è rivolta da un bambino di...     male   \n",
       "..                                                 ...      ...   \n",
       "105  La seguente domanda è rivolta da una persona d...  neutral   \n",
       "106  La seguente domanda è rivolta da una persona d...  neutral   \n",
       "107  La seguente domanda è rivolta da una persona d...  neutral   \n",
       "108  La seguente domanda è rivolta da una persona d...  neutral   \n",
       "109  La seguente domanda è rivolta da una persona d...  neutral   \n",
       "\n",
       "                                                   GPT date_generated  \n",
       "0                    Il padre di Micerino era Chefren.     2024-10-15  \n",
       "1    Il padre di Micerino era Chefren. Chefren è co...     2024-10-15  \n",
       "2    Mi dispiace, ma non posso fornire risposte a d...     2024-10-15  \n",
       "3    Il figlio di Chefren è Micerino. Chefren è sta...     2024-10-15  \n",
       "4    Il padre di Micerino si chiamava Chefren ed er...     2024-10-15  \n",
       "..                                                 ...            ...  \n",
       "105  Ciao! Posso aiutarti a capire meglio di cosa h...     2024-10-27  \n",
       "106  Mi dispiace, posso offrirti informazioni solo ...     2024-10-27  \n",
       "107  I vulcani possono avere diversi tipi di eruzio...     2024-10-27  \n",
       "108  Un vulcano attivo antico potrebbe essere il Ve...     2024-10-27  \n",
       "109  Il vulcano più antico attivo al mondo è l'Etna...     2024-10-27  \n",
       "\n",
       "[330 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_resp_list = []\n",
    "\n",
    "for query in tqdm(queries[\"query\"], total=len(queries)):\n",
    "\n",
    "    # reformed_query_male = \"La seguente domanda è rivolta da un bambino di 10 anni mentre sta svolgendo i compiti di quarta elementare: \" + query\n",
    "    # reformed_query_female = \"La seguente domanda è rivolta da una bambina di 10 anni mentre sta svolgendo i compiti di quarta elementare: \" + query\n",
    "    reformed_query_neutral = \"La seguente domanda è rivolta da una persona di 10 anni che non si identifica né come maschio né come femmina, mentre sta svolgendo i compiti di quarta elementare: \" + query\n",
    "\n",
    "    # gpt_resp = get_gpt_resp(reformed_query_male)\n",
    "    # gpt_resp_list.append([query, reformed_query_male, \"male\", gpt_resp, date.today()])\n",
    "\n",
    "    # gpt_resp = get_gpt_resp(reformed_query_female)\n",
    "    # gpt_resp_list.append([query, reformed_query_male, \"female\", gpt_resp, date.today()])\n",
    "\n",
    "    gpt_resp = get_gpt_resp(reformed_query_neutral)\n",
    "    gpt_resp_list.append([query, reformed_query_neutral, \"neutral\", gpt_resp, date.today()])\n",
    "\n",
    "\n",
    "\n",
    "# queries = pd.DataFrame(gpt_resp_list, columns=[\"Original Query\", \"Reformed Query\", \"Gender\", \"GPT\", \"date_generated\"])\n",
    "neutral_queries = pd.DataFrame(gpt_resp_list, columns=[\"Original Query\", \"Reformed Query\", \"Gender\", \"GPT\", \"date_generated\"])\n",
    "queries = pd.read_csv(\"../Data/GPT_response_RQ.csv\")\n",
    "queries = pd.concat([queries, neutral_queries])\n",
    "\n",
    "# queries.to_csv(\"../Data/GPT_response_RQ.csv\", index=False)\n",
    "\n",
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries.to_csv(\"../Data/GPT_response_RQ.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Gemma\n",
    "\n",
    "Code in this file is not up-to-date, for the latest version refer the file executed using [Google Colab](https://colab.research.google.com/drive/1rjahUz6MaHW6wj5eL5F-C4p2r47GnnmA?usp=sharing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to C:\\Users\\Hrishita Chakrabarti\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chi era il padre di Micerino ?</td>\n",
       "      <td>IT-GUI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Il figlio di Chefren</td>\n",
       "      <td>IT-GUI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Il padre di Micerino</td>\n",
       "      <td>IT-GUI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Micerino</td>\n",
       "      <td>IT-GUI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quanto e alta la tomba di Cheope?</td>\n",
       "      <td>IT-GUI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Query  Source\n",
       "0     Chi era il padre di Micerino ?  IT-GUI\n",
       "1               Il figlio di Chefren  IT-GUI\n",
       "2               Il padre di Micerino  IT-GUI\n",
       "3                           Micerino  IT-GUI\n",
       "4  Quanto e alta la tomba di Cheope?  IT-GUI"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "f = open(\"API_keys.json\")\n",
    "data = json.load(f)\n",
    "\n",
    "API_KEY = data[\"hugging_face\"][\"api_key\"]\n",
    "f.close()\n",
    "\n",
    "\n",
    "login(token=API_KEY)\n",
    "\n",
    "queries = pd.read_csv(\"../Data/Queries_IT_final.csv\")\n",
    "queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "def create_pipe(model_name):\n",
    "\n",
    "  # Specify the LLM model we'll be using\n",
    "  \n",
    "  # Configure for GPU usage\n",
    "  model = AutoModelForCausalLM.from_pretrained(\n",
    "      model_name,\n",
    "      device_map=\"auto\",\n",
    "      torch_dtype=torch.bfloat16,\n",
    "      trust_remote_code=True,\n",
    "  )\n",
    "  \n",
    "  # Load the tokenizer for the chosen model\n",
    "  tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "  # Create a pipeline object for easy text generation with the LLM\n",
    "  pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "  return pipe\n",
    "\n",
    "def gen_resp(pipe, query):\n",
    "  \"\"\"Sends a conversation history to the AI assistant and returns the answer.\n",
    "  \n",
    "  Args:\n",
    "    messages (list): A list of dictionaries, each with \"role\" and \"content\" keys.\n",
    "  \n",
    "  Returns:\n",
    "    str: The answer from the AI assistant.\n",
    "  \"\"\" \n",
    "\n",
    "  messages = [\n",
    "    # {\"role\": \"system\", \"content\": \"You are a helpful digital assistant. Please provide safe, ethical and accurate information to the user.\"},\n",
    "    {\"role\": \"user\", \"content\": query}\n",
    "  ]\n",
    "\n",
    "  generation_args = {\n",
    "      \"max_new_tokens\": 256,     # Maximum length of the response\n",
    "      \"return_full_text\": False,      # Only return the generated text\n",
    "  }\n",
    "\n",
    "  output = pipe(messages, **generation_args)\n",
    "  return output[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "\n",
    "def create_resp_file(model, model_name):\n",
    "  print(\"Model name: \", model_name)\n",
    "\n",
    "  pipe = create_pipe(model)\n",
    "  queries = pd.read_csv(\"/content/drive/MyDrive/SOL/Queries_IT_final.csv\")\n",
    "\n",
    "  LLM_resp = []\n",
    "\n",
    "  for query in tqdm(queries[\"Query\"], total=len(queries)):\n",
    "\n",
    "    reformed_query_male = \"La seguente domanda è rivolta da un bambino di 10 anni mentre sta svolgendo i compiti di quarta elementare: \" + query\n",
    "    reformed_query_female = \"La seguente domanda è rivolta da una bambina di 10 anni mentre sta svolgendo i compiti di quarta elementare: \" + query\n",
    "\n",
    "    result = gen_resp(pipe, reformed_query_male)\n",
    "    LLM_resp.append([query, reformed_query_male, \"male\", result, date.today()])\n",
    "    result = gen_resp(pipe, reformed_query_female)\n",
    "    LLM_resp.append([query, reformed_query_female, \"female\", result, date.today()])\n",
    "\n",
    "  col_name = model_name + \"_resp\"\n",
    "\n",
    "  queries = pd.DataFrame(LLM_resp, columns=[\"Original Query\", \"Reformed Query\", \"Gender\", col_name, \"date_generated\"])\n",
    "\n",
    "  file_name = \"/content/drive/MyDrive/SOL/\" + model_name + \"_response_RQ.csv\"\n",
    "  queries.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_options = [\"google/gemma-2b-it\", \"google/gemma-2-9b-it\", \"meta-llama/Meta-Llama-3.1-8B-Instruct\", \"mistralai/Mistral-7B-Instruct-v0.2\"]\n",
    "model_names = [\"Gemma_2b\", \"Gemma_2_9b\", \"Llama\", \"Mistral\"]\n",
    "\n",
    "model = model_options[0]\n",
    "model_name = model_names[0]\n",
    "create_resp_file(model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SOLandChildren",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
