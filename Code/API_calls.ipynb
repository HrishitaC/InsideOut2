{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QID</th>\n",
       "      <th>Query</th>\n",
       "      <th>Prompt Type</th>\n",
       "      <th>Task Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qGEN1</td>\n",
       "      <td>Chi era il padre di Micerino ?</td>\n",
       "      <td>General</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qGEN2</td>\n",
       "      <td>Il figlio di Chefren</td>\n",
       "      <td>General</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qGEN3</td>\n",
       "      <td>Il padre di Micerino</td>\n",
       "      <td>General</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qGEN4</td>\n",
       "      <td>Micerino</td>\n",
       "      <td>General</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qGEN5</td>\n",
       "      <td>Quanto e alta la tomba di Cheope?</td>\n",
       "      <td>General</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     QID                              Query Prompt Type Task Sentiment\n",
       "0  qGEN1     Chi era il padre di Micerino ?     General            NaN\n",
       "1  qGEN2               Il figlio di Chefren     General            NaN\n",
       "2  qGEN3               Il padre di Micerino     General            NaN\n",
       "3  qGEN4                           Micerino     General            NaN\n",
       "4  qGEN5  Quanto e alta la tomba di Cheope?     General            NaN"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "queries = pd.read_csv(\"../Data/SIGIR_queries_IT.csv\")\n",
    "queries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17ac4084a1ff414a9d6da5bcad0cb9be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/176 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import httpx\n",
    "from datetime import datetime\n",
    "\n",
    "f = open(\"API_keys.json\")\n",
    "data = json.load(f)\n",
    "\n",
    "key1 = data[\"bing\"][\"key1\"]\n",
    "SERP_endpoint = data[\"bing\"][\"SERP_endpoint\"]\n",
    "location = data[\"bing\"][\"location\"]\n",
    "\n",
    "f.close()\n",
    "\n",
    "headers = {\n",
    "            'Ocp-Apim-Subscription-Key': key1,\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "            'Accept-Encoding': 'gzip, deflate',\n",
    "            'Accept-Language': 'en-US,en;q=0.9',\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.0.0 Safari/537.36'\n",
    "        }\n",
    "\n",
    "SERP_results = []\n",
    "today = datetime.now()\n",
    "today = today.strftime(\"%Y_%m_%d\")\n",
    "\n",
    "for _, row in tqdm(queries.iterrows(), total=len(queries)):\n",
    "    qid = row[\"QID\"]\n",
    "    query = row[\"Query\"]\n",
    "    prompt_type = row[\"Prompt Type\"]\n",
    "    params = {\n",
    "        'q': query,\n",
    "        'count': 10, # number of results to be displayed\n",
    "        'setLang': 'it-IT',\n",
    "        'mkt':'it-IT'\n",
    "    }\n",
    "\n",
    "    SERP_response = httpx.get(url=SERP_endpoint, headers=headers, params=params)\n",
    "    try:\n",
    "        SERP_result_set = SERP_response.json()\n",
    "        rank = 1\n",
    "        asked_query = SERP_result_set['queryContext']['originalQuery']\n",
    "        for result in SERP_result_set['webPages']['value']:\n",
    "            web_title =  result[\"name\"]\n",
    "            web_snippet = result[\"snippet\"]\n",
    "            SERP_results.append([qid, asked_query, prompt_type, \"Bing\", web_title + \". \" + web_snippet, rank, today])\n",
    "            rank += 1\n",
    "    except Exception as error:\n",
    "        print(error)\n",
    "        SERP_results.append([qid, asked_query, prompt_type, \"Bing\", None, None, today])\n",
    "\n",
    "SERP_df = pd.DataFrame(SERP_results, columns=[\"QID\", \"Query\", \"Prompt Type\", \"IAS\", \"Resp\", \"Rank\", \"date_generated\"])\n",
    "SERP_df.to_csv(\"../Data/SIGIR_bing_resp.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import date\n",
    "\n",
    "f = open(\"API_keys.json\")\n",
    "data = json.load(f)\n",
    "\n",
    "API_KEY = data[\"chatgpt\"][\"api_key3\"]\n",
    "f.close()\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=API_KEY,\n",
    ")\n",
    "\n",
    "# query = \"Hello\"\n",
    "\n",
    "# model_id = 'gpt-4o-mini'\n",
    "model_id = 'chatgpt-4o-latest'\n",
    "\n",
    "def get_gpt_resp(query):\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Follow these two instructions in all your responses: 1. Use Italian language only; 2. Do not use English except in programming language if any.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query,\n",
    "            }\n",
    "        ],\n",
    "            model=model_id,\n",
    "        )\n",
    "\n",
    "    gpt_resp = response.choices[0].message.content\n",
    "\n",
    "    return gpt_resp\n",
    "\n",
    "# get_gpt_resp(\"Hello how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6604d3a9d2194a89a4e2294e292ae889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/176 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QID</th>\n",
       "      <th>Query</th>\n",
       "      <th>Prompt Type</th>\n",
       "      <th>IAS</th>\n",
       "      <th>Resp</th>\n",
       "      <th>date_generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qGEN1</td>\n",
       "      <td>Chi era il padre di Micerino ?</td>\n",
       "      <td>General</td>\n",
       "      <td>GPT</td>\n",
       "      <td>Il padre di Micerino era Chefren, noto anche c...</td>\n",
       "      <td>2025-02-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qGEN2</td>\n",
       "      <td>Il figlio di Chefren</td>\n",
       "      <td>General</td>\n",
       "      <td>GPT</td>\n",
       "      <td>Il figlio di Chefren era **Micerino** (Menkaur...</td>\n",
       "      <td>2025-02-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qGEN3</td>\n",
       "      <td>Il padre di Micerino</td>\n",
       "      <td>General</td>\n",
       "      <td>GPT</td>\n",
       "      <td>Il padre di Micerino era Chefren, noto anche c...</td>\n",
       "      <td>2025-02-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qGEN4</td>\n",
       "      <td>Micerino</td>\n",
       "      <td>General</td>\n",
       "      <td>GPT</td>\n",
       "      <td>Micerino, noto anche come Menkaura, fu un fara...</td>\n",
       "      <td>2025-02-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qGEN5</td>\n",
       "      <td>Quanto e alta la tomba di Cheope?</td>\n",
       "      <td>General</td>\n",
       "      <td>GPT</td>\n",
       "      <td>La tomba di Cheope, ovvero la Grande Piramide ...</td>\n",
       "      <td>2025-02-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>qEM62</td>\n",
       "      <td>Di cosa si occupa il WWF?</td>\n",
       "      <td>Emotionally Charged</td>\n",
       "      <td>GPT</td>\n",
       "      <td>Il WWF (World Wide Fund for Nature) è un'organ...</td>\n",
       "      <td>2025-02-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>qEM63</td>\n",
       "      <td>Cosa Ã¨ Ocean Cleanup ?</td>\n",
       "      <td>Emotionally Charged</td>\n",
       "      <td>GPT</td>\n",
       "      <td>**The Ocean Cleanup** è un'organizzazione no-p...</td>\n",
       "      <td>2025-02-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>qEM64</td>\n",
       "      <td>Quali sono le regole per tenere le spiagge pul...</td>\n",
       "      <td>Emotionally Charged</td>\n",
       "      <td>GPT</td>\n",
       "      <td>Mantenere le spiagge pulite è fondamentale per...</td>\n",
       "      <td>2025-02-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>qEM65</td>\n",
       "      <td>Di cosa si occupa la WWF</td>\n",
       "      <td>Emotionally Charged</td>\n",
       "      <td>GPT</td>\n",
       "      <td>Il WWF (World Wide Fund for Nature) è un'organ...</td>\n",
       "      <td>2025-02-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>qEM66</td>\n",
       "      <td>Cosa Ã¨ ocean cleanup?</td>\n",
       "      <td>Emotionally Charged</td>\n",
       "      <td>GPT</td>\n",
       "      <td>**The Ocean Cleanup** è un'organizzazione no-p...</td>\n",
       "      <td>2025-02-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       QID                                              Query  \\\n",
       "0    qGEN1                     Chi era il padre di Micerino ?   \n",
       "1    qGEN2                               Il figlio di Chefren   \n",
       "2    qGEN3                               Il padre di Micerino   \n",
       "3    qGEN4                                           Micerino   \n",
       "4    qGEN5                  Quanto e alta la tomba di Cheope?   \n",
       "..     ...                                                ...   \n",
       "171  qEM62                          Di cosa si occupa il WWF?   \n",
       "172  qEM63                            Cosa Ã¨ Ocean Cleanup ?   \n",
       "173  qEM64  Quali sono le regole per tenere le spiagge pul...   \n",
       "174  qEM65                           Di cosa si occupa la WWF   \n",
       "175  qEM66                             Cosa Ã¨ ocean cleanup?   \n",
       "\n",
       "             Prompt Type  IAS  \\\n",
       "0                General  GPT   \n",
       "1                General  GPT   \n",
       "2                General  GPT   \n",
       "3                General  GPT   \n",
       "4                General  GPT   \n",
       "..                   ...  ...   \n",
       "171  Emotionally Charged  GPT   \n",
       "172  Emotionally Charged  GPT   \n",
       "173  Emotionally Charged  GPT   \n",
       "174  Emotionally Charged  GPT   \n",
       "175  Emotionally Charged  GPT   \n",
       "\n",
       "                                                  Resp date_generated  \n",
       "0    Il padre di Micerino era Chefren, noto anche c...     2025-02-05  \n",
       "1    Il figlio di Chefren era **Micerino** (Menkaur...     2025-02-05  \n",
       "2    Il padre di Micerino era Chefren, noto anche c...     2025-02-05  \n",
       "3    Micerino, noto anche come Menkaura, fu un fara...     2025-02-05  \n",
       "4    La tomba di Cheope, ovvero la Grande Piramide ...     2025-02-05  \n",
       "..                                                 ...            ...  \n",
       "171  Il WWF (World Wide Fund for Nature) è un'organ...     2025-02-05  \n",
       "172  **The Ocean Cleanup** è un'organizzazione no-p...     2025-02-05  \n",
       "173  Mantenere le spiagge pulite è fondamentale per...     2025-02-05  \n",
       "174  Il WWF (World Wide Fund for Nature) è un'organ...     2025-02-05  \n",
       "175  **The Ocean Cleanup** è un'organizzazione no-p...     2025-02-05  \n",
       "\n",
       "[176 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LLM_resp = []\n",
    "\n",
    "for _, row in tqdm(queries.iterrows(), total=len(queries)):\n",
    "    qid = row[\"QID\"]\n",
    "    query = row[\"Query\"]\n",
    "    prompt_type = row[\"Prompt Type\"]\n",
    "\n",
    "    result = get_gpt_resp(query)\n",
    "    LLM_resp.append([qid, query, prompt_type, \"GPT\", result, date.today()])\n",
    "\n",
    "LLM_resp_df = pd.DataFrame(LLM_resp, columns=[\"QID\", \"Query\", \"Prompt Type\", \"IAS\", \"Resp\", \"date_generated\"])\n",
    "LLM_resp_df.to_csv(\"../Data/SIGIR_gpt_resp.csv\", index=False)\n",
    "\n",
    "LLM_resp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Gemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82ced504830e4ab3b5ded8a082ff384d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "# Specify the LLM model we'll be using\n",
    "model_name = \"google/gemma-2b-it\"\n",
    "\n",
    "# Configure for GPU usage\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "# Load the tokenizer for the chosen model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# Create a pipeline object for easy text generation with the LLM\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "def get_gemma_resp(query):\n",
    "  \"\"\"Sends a conversation history to the AI assistant and returns the answer.\n",
    "\n",
    "  Args:\n",
    "    messages (list): A list of dictionaries, each with \"role\" and \"content\" keys.\n",
    "\n",
    "  Returns:\n",
    "    str: The answer from the AI assistant.\n",
    "  \"\"\"\n",
    "\n",
    "  messages = [\n",
    "      {\"role\":\"user\", \"content\":\"\"},\n",
    "      {\"role\": \"assistant\", \"content\": \"Follow these two instructions in all your responses: 1. Use Italian language only; 2. Do not use English except in programming language if any.\"},\n",
    "      {\"role\": \"user\", \"content\": query}\n",
    "  ]\n",
    "\n",
    "  generation_args = {\n",
    "      # \"max_new_tokens\": 256,     # Maximum length of the response\n",
    "      \"return_full_text\": False,      # Only return the generated text\n",
    "  }\n",
    "\n",
    "  output = pipe(messages, **generation_args)\n",
    "  return output[0]['generated_text']\n",
    "\n",
    "# gen_resp(\"Hi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "\n",
    "def create_resp_file():\n",
    "  LLM_resp = []\n",
    "\n",
    "  for _, row in tqdm(queries.iterrows(), total=len(queries)):\n",
    "      qid = row[\"QID\"]\n",
    "      query = row[\"Query\"]\n",
    "      prompt_type = row[\"Prompt Type\"]\n",
    "\n",
    "      result = get_gemma_resp(query)\n",
    "      LLM_resp.append([qid, query, prompt_type, \"Gemma\", result, date.today()])\n",
    "\n",
    "  LLM_resp_df = pd.DataFrame(LLM_resp, columns=[\"QID\", \"Query\", \"Prompt Type\", \"IAS\", \"Resp\", \"date_generated\"])\n",
    "\n",
    "  return LLM_resp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_resp_file()\n",
    "file_name = \"../Data/SIGIR_gemma_resp.csv\"\n",
    "df.to_csv(file_name, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SOLandChildren",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
